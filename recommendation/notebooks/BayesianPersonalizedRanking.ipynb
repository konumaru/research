{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86fc4b10-3547-47b0-aede-49b42edc5dab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bayesian Personalized Ranking From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d12131-6a65-43e7-be51-297072c13609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "828d2cfc-6539-4972-ad3c-4cb5005c7fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Ethen\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.7\n",
      "IPython version      : 7.30.1\n",
      "\n",
      "numpy  : 1.21.4\n",
      "pandas : 1.3.5\n",
      "scipy  : 1.7.3\n",
      "sklearn: 1.0.1\n",
      "tqdm   : 4.62.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from itertools import islice\n",
    "from math import ceil\n",
    "from subprocess import call\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, dok_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import trange\n",
    "\n",
    "%watermark -a 'Ethen' -d -t -v -p numpy,pandas,scipy,sklearn,tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52cc0950-68d2-4a2e-a8f5-c87678709249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"../data/\"\n",
    "file_dir = os.path.join(data_dir, \"ml-100k\")\n",
    "file_path = os.path.join(data_dir, file_dir, \"u.data\")\n",
    "\n",
    "if not os.path.isdir(file_dir):\n",
    "    call([\"curl\", \"-O\", \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"])\n",
    "    call([\"unzip\", \"ml-100k.zip\", \"-d\", \"../data/\"])\n",
    "    call([\"rm\", \"ml-100k.zip\"])\n",
    "\n",
    "names = [\"user_id\", \"item_id\", \"rating\", \"timestamp\"]\n",
    "df = pd.read_csv(file_path, sep=\"\\t\", names=names)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f693bf57-6a3e-4d1f-8a14-c4ba4614102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(data, users_col, items_col, ratings_col, threshold=None):\n",
    "    \"\"\"Create the sparse user-item interaction matrix,\n",
    "    if the data is not in the format where the interaction only\n",
    "    contains the positive items (indicated by 1), then use the\n",
    "    threshold parameter to determine which items are considered positive\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : DataFrame\n",
    "        implicit raging data\n",
    "\n",
    "    users_col : str\n",
    "        user column name\n",
    "\n",
    "    items_col : str\n",
    "        item column name\n",
    "\n",
    "    ratings_col : str\n",
    "        implicit rating column name\n",
    "\n",
    "    threshold : int, default None\n",
    "        threshold to determine whether th user-item pair is\n",
    "        a positive feedback\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ratings : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "        user/item ratings martix\n",
    "\n",
    "    data : DataFrame\n",
    "        implicit rating data that retains only the positive feedback\n",
    "        (if specified to do so)\n",
    "    \"\"\"\n",
    "    if threshold is not None:\n",
    "        data = data[data[ratings_col] >= threshold].copy()\n",
    "        data[ratings_col] = 1\n",
    "\n",
    "    for col in (items_col, users_col, ratings_col):\n",
    "        data[col] = data[col].copy().astype(\"category\")\n",
    "\n",
    "    ratings = csr_matrix(\n",
    "        (data[ratings_col], (data[users_col].cat.codes, data[items_col].cat.codes))\n",
    "    )\n",
    "    ratings.eliminate_zeros()\n",
    "    return ratings, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34a86481-d4fb-4626-ad77-b34535191363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<943x1574 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 82520 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_col = \"user_id\"\n",
    "items_col = \"item_id\"\n",
    "ratings_col = \"rating\"\n",
    "threshold = 3\n",
    "X, df = create_matrix(df, users_col, items_col, ratings_col, threshold)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d160c6ad-6e0d-42de-88a0-a0efca01ede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(ratings, test_size=0.2, seed=1234):\n",
    "    \"\"\"Split the user-item interaction matrix into train and test set\n",
    "    by removing some of the interactions from every user and pretend\n",
    "    that we never seen them\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ratings : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "        The user-item interactions matrix\n",
    "\n",
    "    test_size : float between 0.0 and 1.0, default 0.2\n",
    "        Proportion of the user-item interactions for each user\n",
    "        in the dataset to move to the test set; e.g. if set to 0.2\n",
    "        and a user has 10 interactions, then 2 will be moved to the\n",
    "        test set\n",
    "\n",
    "    seed : int, default 1234\n",
    "        Seed for reproducible random splitting the\n",
    "        data into train/test set\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "        Training set\n",
    "\n",
    "    test : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "        Test set\n",
    "    \"\"\"\n",
    "    assert test_size < 1.0 and test_size > 0.0\n",
    "\n",
    "    # Dictionary Of Keys based sparse matrix is more efficient\n",
    "    # for constructing sparse matries incrementally compared with csr_matrix\n",
    "    train = ratings.copy().todok()\n",
    "    test = dok_matrix(train.shape)\n",
    "\n",
    "    # for all the users assign randomly chosen interactions\n",
    "    # to the test and assign those interactions to zeoro in training;\n",
    "    # when computing the interactions to go into the test set,\n",
    "    # remenber to round up the numbers (e.g. a user has 4 ratings, if the\n",
    "    # test_size is 0.2, the 0.8 ratings will go to test, thus we need to\n",
    "    # round up to ensure the test set gets at least 1 rating)\n",
    "    rstate = np.random.RandomState(seed)\n",
    "    for u in range(ratings.shape[0]):\n",
    "        split_index = ratings[u].indices\n",
    "        n_splits = ceil(test_size * split_index.shape[0])\n",
    "        test_index = rstate.choice(split_index, size=n_splits, replace=False)\n",
    "        test[u, test_index] = ratings[u, test_index]\n",
    "        train[u, test_index] = 0\n",
    "\n",
    "    train, test = train.tocsr(), test.tocsr()\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59d0d5d7-77a1-4b6d-afb2-8202b1af7f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<943x1574 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 65641 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = create_train_test(X, test_size=0.2, seed=1234)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d53cb076-9470-42d3-a9e4-65623627b5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPR:\n",
    "    \"\"\"Baysian Personalized Ranking (BPR) for implicit feedback data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    learning_rate : float, default 0.01\n",
    "        learning rate for gradient descent\n",
    "\n",
    "    n_factors : int, default 20\n",
    "        Number/dimension of user and item latent factors\n",
    "\n",
    "    batch_size : int, default 1000\n",
    "        batch size for batch gradient descent, the original paper\n",
    "        uses stochastic gradient descent (i.e., batch size of 1),\n",
    "        but this can make the training unstable (very sensitive to\n",
    "        learning rate)\n",
    "\n",
    "    reg : int, default 0.01\n",
    "        Regularization term for the user and item latent factors\n",
    "\n",
    "    seed : int, default 1234\n",
    "        Seed for the randomly initialized user, item latent factors\n",
    "\n",
    "    verbose : bool, default True\n",
    "        Whether to print progress bar while training\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    user_factors : 2d ndarray, shape [n_users, n_factors]\n",
    "        User latent factors learnt\n",
    "\n",
    "    item_factors : 2d ndarray, shape [n_items, n_factors]\n",
    "        Item latent factors learnt\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    S. Rendle, C. Freudenthaler, Z. Gantner, L. Schmidt-Thieme\n",
    "    Bayesian Personalized Ranking from Implicit Feedback\n",
    "    - https://arxiv.org/abs/1205.2618\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate=0.01,\n",
    "        n_factors=15,\n",
    "        n_iters=10,\n",
    "        batch_size=1000,\n",
    "        reg=0.01,\n",
    "        seed=1234,\n",
    "        verbose=True,\n",
    "    ):\n",
    "        self.reg = reg\n",
    "        self.seed = seed\n",
    "        self.verbose = verbose\n",
    "        self.n_iters = n_iters\n",
    "        self.n_factors = n_factors\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # to avoid re-computation at predict\n",
    "        self._prediction = None\n",
    "\n",
    "    def fit(self, ratings):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        ratings : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "            sparse matrix of user-item interactions\n",
    "        \"\"\"\n",
    "        indptr = ratings.indptr\n",
    "        indices = ratings.indices\n",
    "        n_users, n_items = ratings.shape\n",
    "\n",
    "        # ensure batch size makes sense, since the algorithm involves\n",
    "        # for each step randomly sample a user, thus the batch size\n",
    "        # should be smaller than the total number of users or else\n",
    "        # we would be sampling the user with replacement\n",
    "        batch_size = self.batch_size\n",
    "        if n_users < batch_size:\n",
    "            batch_size = n_users\n",
    "            sys.stderr.write(\n",
    "                \"WARNING: Batch size is greater than number of users,　\"\n",
    "                \"swiching to a batch size of {}\\n\".format(n_users)\n",
    "            )\n",
    "\n",
    "        batch_iters = n_users // batch_size\n",
    "        # Initialize random weights\n",
    "        rstate = np.random.RandomState(self.seed)\n",
    "        self.user_factors = rstate.normal(size=(n_users, self.n_factors))\n",
    "        self.item_factors = rstate.normal(size=(n_items, self.n_factors))\n",
    "\n",
    "        # progress bar for training iteration if verbose is turned on\n",
    "        loop = range(self.n_iters)\n",
    "        if self.verbose:\n",
    "            loop = trange(self.n_iters, desc=self.__class__.__name__)\n",
    "\n",
    "        for _ in loop:\n",
    "            for _ in range(batch_iters):\n",
    "                sampled = self._sample(n_users, n_items, indices, indptr)\n",
    "                sampled_users, sampled_pos_items, sampled_neg_items = sampled\n",
    "                self._update(sampled_users, sampled_pos_items, sampled_neg_items)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _sample(self, n_users, n_items, indices, indptr):\n",
    "        \"\"\"Sample batches of random triplets u, i, j\"\"\"\n",
    "        sampled_pos_items = np.zeros(self.batch_size, dtype=np.int)\n",
    "        sampled_neg_items = np.zeros(self.batch_size, dtype=np.int)\n",
    "        sampled_users = np.random.choice(n_users, size=self.batch_size, replace=False)\n",
    "\n",
    "        for idx, user in enumerate(sampled_users):\n",
    "            pos_items = indices[indptr[user] : indptr[user + 1]]\n",
    "            pos_item = np.random.choice(pos_items)\n",
    "            neg_item = np.random.choice(n_items)\n",
    "            while neg_item in pos_items:\n",
    "                neg_item = np.random.choice(n_items)\n",
    "\n",
    "            sampled_pos_items[idx] = pos_item\n",
    "            sampled_neg_items[idx] = neg_item\n",
    "\n",
    "        return sampled_users, sampled_pos_items, sampled_neg_items\n",
    "\n",
    "    def _update(self, u, i, j):\n",
    "        \"\"\"Update according to the bootstrapped user u,\n",
    "        positive item i and negative item j\n",
    "        \"\"\"\n",
    "        user_u = self.user_facotrs[u]\n",
    "        item_i = self.item_factors[i]\n",
    "        item_j = self.item_factors[j]\n",
    "\n",
    "        # decompose the estimator, compute the difference between\n",
    "        # the score of the positive items and negative items; a\n",
    "        # native implementation might look like the following:\n",
    "        # r_ui = np.diag(user_u.dot(item_i.T))\n",
    "        # r_uj = np.diag(user_u.dot(item_j.T))\n",
    "        # r_uij = r_ui - r_uj\n",
    "\n",
    "        # however, we can do better, so\n",
    "        # for batch dot product, instead of doing the dot product\n",
    "        # then only extract the diagonal element (which is the value\n",
    "        # of that current batch), we perform a hadamard product,\n",
    "        # i.e. matrix element-wise product then do a sum along the column will\n",
    "        # be more efficient since it's less operations\n",
    "        # http://poeple.revoledu.com/kardi/tutorial/LinearAlgebra/HadamarProduct.html\n",
    "        # r_ui = np.sum(user_u * item_i, axis=1)\n",
    "        #\n",
    "        # then we can achieve another speedup by doing the difference\n",
    "        # on the positive and negative item up front instead of computing\n",
    "        # r_ui and r_uj separately, these two idea will speed up the operations\n",
    "        # from 1:14 down to 0.36\n",
    "        r_uij = np.sum(user_u * (item_i - item_j), axis=1)\n",
    "        sigmoid = np.exp(-r_uij) / (1.0 + np.exp(-r_uij))\n",
    "        \n",
    "        # repeat the 1 dimension sigmoid n_factors times so \n",
    "        # the dimension will match when doing the update\n",
    "        sigmoid_tiled = np.tile(sigmoid, (self.n_factors, 1)).T\n",
    "        \n",
    "        # update using gradient descent\n",
    "        grad_u = sigmoid_tiled * (item_j - item_i) + self.reg * user_u\n",
    "\n",
    "    def predict(self):\n",
    "        pass\n",
    "\n",
    "    def _predict_user(self, user):\n",
    "        pass\n",
    "\n",
    "    def recommend(self, ratings, N=5):\n",
    "        pass\n",
    "\n",
    "    def _recommend_user(self, ratings, user, N):\n",
    "        pass\n",
    "\n",
    "    def get_similar_items(self, N=5, item_ids=None):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9147be1e-1f17-46d4-9c66-df8fec70edce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BPR:   0%|                                                                                                                | 0/160 [00:00<?, ?it/s]/tmp/ipykernel_25/3819263579.py:107: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sampled_pos_items = np.zeros(self.batch_size, dtype=np.int)\n",
      "/tmp/ipykernel_25/3819263579.py:108: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sampled_neg_items = np.zeros(self.batch_size, dtype=np.int)\n",
      "BPR: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 160/160 [00:01<00:00, 89.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.BPR at 0xffff60358eb0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters were randomly chosen\n",
    "bpr_params = {\n",
    "    \"reg\": 0.01,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_iters\": 160,\n",
    "    \"n_factors\": 15,\n",
    "    \"batch_size\": 100,\n",
    "}\n",
    "\n",
    "bpr = BPR(**bpr_params)\n",
    "bpr.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d03c32-2304-4599-9c4a-937a8da94f7a",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dfabe8-7927-4887-a254-54103e2f2374",
   "metadata": {},
   "source": [
    "## Item Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e10f85-01b9-49f1-8aaa-6a727529b296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3493ea88-e68c-4023-935e-291e56bb571f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb500327-0c92-4391-b06f-0f3aa028ccdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680ccc43-d5a0-47a6-99a3-c0f31700deb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17cf9026-0cac-49b4-925c-10157898b1e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reference\n",
    "\n",
    "- http://ethen8181.github.io/machine-learning/recsys/4_bpr.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
